# ChatGLM1

**Prefix Decoder-only** Bilingual Model

Pre-training Data

* The vocabulary size is 150528.

Architecture

* Post-LN initialized with DeepNorm
* GeLU activation function
* Rotary Embeddings

